{"metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.11", "language": "python"}, "language_info": {"name": "python", "version": "3.11.13", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat_minor": 4, "nbformat": 4, "cells": [{"cell_type": "code", "source": "\nimport os, types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\n\ncos_client = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='mC9MOAZs2JOS7JCXOiJavBQ6bAYpqDg8MZrkRXM_J4IV',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/identity/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.direct.au-syd.cloud-object-storage.appdomain.cloud')\n\nbucket = 'gnnml-donotdelete-pr-a7n66qygvumdpb'\nobject_key = 'Train_data.csv'\n\nbody = cos_client.get_object(Bucket=bucket,Key=object_key)['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ndf = pd.read_csv(body)\ndf.head(10)\n", "metadata": {"id": "e397f24f-070d-428e-83ae-b07b62b997a3"}, "outputs": [{"execution_count": 1, "output_type": "execute_result", "data": {"text/plain": "   duration protocol_type     service flag  src_bytes  dst_bytes  land  \\\n0         0           tcp    ftp_data   SF        491          0     0   \n1         0           udp       other   SF        146          0     0   \n2         0           tcp     private   S0          0          0     0   \n3         0           tcp        http   SF        232       8153     0   \n4         0           tcp        http   SF        199        420     0   \n5         0           tcp     private  REJ          0          0     0   \n6         0           tcp     private   S0          0          0     0   \n7         0           tcp     private   S0          0          0     0   \n8         0           tcp  remote_job   S0          0          0     0   \n9         0           tcp     private   S0          0          0     0   \n\n   wrong_fragment  urgent  hot  ...  dst_host_srv_count  \\\n0               0       0    0  ...                  25   \n1               0       0    0  ...                   1   \n2               0       0    0  ...                  26   \n3               0       0    0  ...                 255   \n4               0       0    0  ...                 255   \n5               0       0    0  ...                  19   \n6               0       0    0  ...                   9   \n7               0       0    0  ...                  15   \n8               0       0    0  ...                  23   \n9               0       0    0  ...                  13   \n\n   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n0                    0.17                    0.03   \n1                    0.00                    0.60   \n2                    0.10                    0.05   \n3                    1.00                    0.00   \n4                    1.00                    0.00   \n5                    0.07                    0.07   \n6                    0.04                    0.05   \n7                    0.06                    0.07   \n8                    0.09                    0.05   \n9                    0.05                    0.06   \n\n   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n0                         0.17                         0.00   \n1                         0.88                         0.00   \n2                         0.00                         0.00   \n3                         0.03                         0.04   \n4                         0.00                         0.00   \n5                         0.00                         0.00   \n6                         0.00                         0.00   \n7                         0.00                         0.00   \n8                         0.00                         0.00   \n9                         0.00                         0.00   \n\n   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n0                  0.00                      0.00                  0.05   \n1                  0.00                      0.00                  0.00   \n2                  1.00                      1.00                  0.00   \n3                  0.03                      0.01                  0.00   \n4                  0.00                      0.00                  0.00   \n5                  0.00                      0.00                  1.00   \n6                  1.00                      1.00                  0.00   \n7                  1.00                      1.00                  0.00   \n8                  1.00                      1.00                  0.00   \n9                  1.00                      1.00                  0.00   \n\n   dst_host_srv_rerror_rate    class  \n0                      0.00   normal  \n1                      0.00   normal  \n2                      0.00  anomaly  \n3                      0.01   normal  \n4                      0.00   normal  \n5                      1.00  anomaly  \n6                      0.00  anomaly  \n7                      0.00  anomaly  \n8                      0.00  anomaly  \n9                      0.00  anomaly  \n\n[10 rows x 42 columns]", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>duration</th>\n      <th>protocol_type</th>\n      <th>service</th>\n      <th>flag</th>\n      <th>src_bytes</th>\n      <th>dst_bytes</th>\n      <th>land</th>\n      <th>wrong_fragment</th>\n      <th>urgent</th>\n      <th>hot</th>\n      <th>...</th>\n      <th>dst_host_srv_count</th>\n      <th>dst_host_same_srv_rate</th>\n      <th>dst_host_diff_srv_rate</th>\n      <th>dst_host_same_src_port_rate</th>\n      <th>dst_host_srv_diff_host_rate</th>\n      <th>dst_host_serror_rate</th>\n      <th>dst_host_srv_serror_rate</th>\n      <th>dst_host_rerror_rate</th>\n      <th>dst_host_srv_rerror_rate</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>tcp</td>\n      <td>ftp_data</td>\n      <td>SF</td>\n      <td>491</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>25</td>\n      <td>0.17</td>\n      <td>0.03</td>\n      <td>0.17</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.05</td>\n      <td>0.00</td>\n      <td>normal</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>udp</td>\n      <td>other</td>\n      <td>SF</td>\n      <td>146</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0.00</td>\n      <td>0.60</td>\n      <td>0.88</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>normal</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>tcp</td>\n      <td>private</td>\n      <td>S0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>26</td>\n      <td>0.10</td>\n      <td>0.05</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>anomaly</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>tcp</td>\n      <td>http</td>\n      <td>SF</td>\n      <td>232</td>\n      <td>8153</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>255</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.03</td>\n      <td>0.04</td>\n      <td>0.03</td>\n      <td>0.01</td>\n      <td>0.00</td>\n      <td>0.01</td>\n      <td>normal</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>tcp</td>\n      <td>http</td>\n      <td>SF</td>\n      <td>199</td>\n      <td>420</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>255</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>normal</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>tcp</td>\n      <td>private</td>\n      <td>REJ</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>19</td>\n      <td>0.07</td>\n      <td>0.07</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>anomaly</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>tcp</td>\n      <td>private</td>\n      <td>S0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>9</td>\n      <td>0.04</td>\n      <td>0.05</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>anomaly</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>tcp</td>\n      <td>private</td>\n      <td>S0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>15</td>\n      <td>0.06</td>\n      <td>0.07</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>anomaly</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0</td>\n      <td>tcp</td>\n      <td>remote_job</td>\n      <td>S0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>23</td>\n      <td>0.09</td>\n      <td>0.05</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>anomaly</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>tcp</td>\n      <td>private</td>\n      <td>S0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>13</td>\n      <td>0.05</td>\n      <td>0.06</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>anomaly</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows \u00d7 42 columns</p>\n</div>"}, "metadata": {}}], "execution_count": 1}, {"cell_type": "code", "source": "!pip install torch_geometric", "metadata": {"id": "0d53f1c6-7607-49df-822a-0bcf6d148be7"}, "outputs": [{"name": "stdout", "text": "Collecting torch_geometric\n  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from torch_geometric) (3.11.10)\nRequirement already satisfied: fsspec in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from torch_geometric) (2023.10.0)\nRequirement already satisfied: jinja2 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from torch_geometric) (3.1.6)\nRequirement already satisfied: numpy in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from torch_geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from torch_geometric) (5.9.0)\nRequirement already satisfied: pyparsing in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from torch_geometric) (3.0.9)\nRequirement already satisfied: requests in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from torch_geometric) (2.32.4)\nRequirement already satisfied: tqdm in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from torch_geometric) (4.66.4)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from aiohttp->torch_geometric) (2.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from aiohttp->torch_geometric) (1.2.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from aiohttp->torch_geometric) (23.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from aiohttp->torch_geometric) (1.4.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from aiohttp->torch_geometric) (6.0.4)\nRequirement already satisfied: propcache>=0.2.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from aiohttp->torch_geometric) (0.2.0)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from aiohttp->torch_geometric) (1.18.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from jinja2->torch_geometric) (2.1.3)\nRequirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from requests->torch_geometric) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from requests->torch_geometric) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from requests->torch_geometric) (1.26.19)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from requests->torch_geometric) (2025.6.15)\nDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: torch_geometric\nSuccessfully installed torch_geometric-2.6.1\n", "output_type": "stream"}], "execution_count": 3}, {"cell_type": "code", "source": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch_geometric.nn import GINConv, GCNConv, global_add_pool, global_mean_pool, global_max_pool\nfrom torch_geometric.data import Data, Batch\nfrom torch_geometric.utils import dropout_adj, add_remaining_self_loops\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, roc_auc_score, f1_score, accuracy_score, precision_score, recall_score\nimport networkx as nx\nfrom tqdm import tqdm\nimport warnings\nimport random\nimport hashlib\nimport json\nimport time\n\n# Suppress warnings for cleaner output\nwarnings.filterwarnings('ignore')\n\n# Set random seeds for reproducibility\ntorch.manual_seed(42)\nnp.random.seed(42)\nrandom.seed(42)\n\n# Determine the device to use (GPU if available, else CPU)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\n# Initialize a dictionary to store training history and metrics\ntraining_history = {\n    'pretrain_losses': [],\n    'pretrain_contrastive_losses': [],\n    'pretrain_reg_losses': [],\n    'pretrain_learning_rates': [],\n    'finetune_losses': [],\n    'finetune_accuracies': [],\n    'finetune_learning_rates': [],\n    'validation_metrics': [],\n    'test_metrics': {},\n    'epoch_times': [],\n    'batch_losses': [],\n    'class_distributions': {},\n    'model_parameters': {},\n    'training_config': {}\n}", "metadata": {"id": "b9a1885c-7061-496d-90f0-293cc9e0a47e"}, "outputs": [{"name": "stdout", "text": "Using device: cpu\n", "output_type": "stream"}], "execution_count": 4}, {"cell_type": "code", "source": "class NetworkGraphDataset(Dataset):\n    def __init__(self, graphs, labels=None, transform=None, scaler=None, fit_scaler=False):\n        # Initialize the dataset with graphs, optional labels, transformations, and a scaler\n        self.graphs = graphs\n        self.labels = labels\n        self.transform = transform\n        self.scaler = scaler\n\n        # Fit the scaler if requested (typically on the training data)\n        if fit_scaler and scaler is not None:\n            all_features = []\n            for graph in graphs:\n                all_features.append(graph.x.numpy())\n            all_features = np.vstack(all_features)\n            self.scaler.fit(all_features)\n\n    def __len__(self):\n        # Return the total number of graphs in the dataset\n        return len(self.graphs)\n\n    def __getitem__(self, idx):\n        # Get a graph and its corresponding label (if available) by index\n        graph = self.graphs[idx].clone()\n\n        # Apply feature scaling if a scaler is provided\n        if self.scaler is not None:\n            graph.x = torch.FloatTensor(self.scaler.transform(graph.x.numpy()))\n\n        # Apply graph transformations (e.g., augmentations)\n        if self.transform:\n            graph = self.transform(graph)\n\n        # Return the graph and label, or just the graph if no labels\n        if self.labels is not None:\n            return graph, self.labels[idx]\n        return graph", "metadata": {"id": "cc007385-d8bd-446e-8b20-f1fe6958644d"}, "outputs": [], "execution_count": 7}, {"cell_type": "code", "source": "class GraphAugmentation:\n    def __init__(self, node_drop_rate=0.01, edge_drop_rate=0.02, feature_mask_rate=0.05, temporal_noise_std=0.02):\n        # Initialize augmentation parameters\n        self.node_drop_rate = node_drop_rate\n        self.edge_drop_rate = edge_drop_rate\n        self.feature_mask_rate = feature_mask_rate\n        self.temporal_noise_std = temporal_noise_std\n\n    def structural_augment(self, graph):\n        # Apply structural augmentations (node and edge dropping)\n        aug_graph = graph.clone()\n\n        # Node dropping\n        if aug_graph.num_nodes > 2 and torch.rand(1, device=aug_graph.x.device) < 0.5:\n            num_drop = max(1, int(aug_graph.num_nodes * self.node_drop_rate))\n            keep_nodes = torch.randperm(aug_graph.num_nodes, device=aug_graph.x.device)[:-num_drop]\n\n            node_mask = torch.zeros(aug_graph.num_nodes, dtype=torch.bool, device=aug_graph.x.device)\n            node_mask[keep_nodes] = True\n\n            edge_mask = node_mask[aug_graph.edge_index[0]] & node_mask[aug_graph.edge_index[1]]\n            aug_graph.edge_index = aug_graph.edge_index[:, edge_mask]\n            if hasattr(aug_graph, 'edge_attr') and aug_graph.edge_attr is not None:\n                aug_graph.edge_attr = aug_graph.edge_attr[edge_mask]\n\n            node_mapping = torch.cumsum(node_mask, dim=0) - 1\n            aug_graph.edge_index = node_mapping[aug_graph.edge_index]\n            aug_graph.x = aug_graph.x[node_mask]\n\n            if hasattr(aug_graph, 'batch'):\n                aug_graph.batch = aug_graph.batch[node_mask]\n\n        # Edge dropping\n        if aug_graph.edge_index.size(1) > 0:\n            aug_graph.edge_index, edge_attr_temp = dropout_adj(\n                aug_graph.edge_index,\n                aug_graph.edge_attr if hasattr(aug_graph, 'edge_attr') else None,\n                p=self.edge_drop_rate,\n                training=True\n            )\n            if hasattr(aug_graph, 'edge_attr') and edge_attr_temp is not None:\n                aug_graph.edge_attr = edge_attr_temp\n\n        return aug_graph\n\n    def attribute_augment(self, graph):\n        # Apply attribute augmentations (feature masking and temporal noise)\n        aug_graph = graph.clone()\n\n        # Feature masking\n        mask = torch.rand(aug_graph.x.shape, device=aug_graph.x.device) < self.feature_mask_rate\n        aug_graph.x = aug_graph.x.clone()\n        aug_graph.x[mask] = 0\n\n        # Temporal noise to edge attributes\n        if hasattr(aug_graph, 'edge_attr') and aug_graph.edge_attr is not None:\n            temporal_indices = [0, 1] if aug_graph.edge_attr.size(1) > 1 else [0]\n            noise = torch.randn(aug_graph.edge_attr[:, temporal_indices].shape, device=aug_graph.edge_attr.device) * self.temporal_noise_std\n            aug_graph.edge_attr = aug_graph.edge_attr.clone()\n            aug_graph.edge_attr[:, temporal_indices] += noise\n\n        return aug_graph\n\n    def __call__(self, graph):\n        # Randomly choose between structural and attribute augmentation\n        if torch.rand(1, device=graph.x.device) < 0.5:\n            return self.structural_augment(graph)\n        else:\n            return self.attribute_augment(graph)", "metadata": {"id": "68d99e4b-b6a2-4b8d-ab5c-151d7643d3a6"}, "outputs": [], "execution_count": 8}, {"cell_type": "code", "source": "class GraphEncoder(nn.Module):\n    def __init__(self, input_dim, hidden_dim=128, num_layers=3, dropout=0.1):\n        super().__init__()\n        self.num_layers = num_layers\n        self.dropout = dropout\n\n        # GINConv layers with batch normalization\n        self.convs = nn.ModuleList()\n        self.batch_norms = nn.ModuleList()\n\n        for i in range(num_layers):\n            if i == 0:\n                conv = GINConv(nn.Sequential(\n                    nn.Linear(input_dim, hidden_dim),\n                    nn.ReLU(),\n                    nn.Linear(hidden_dim, hidden_dim)\n                ))\n            else:\n                conv = GINConv(nn.Sequential(\n                    nn.Linear(hidden_dim, hidden_dim),\n                    nn.ReLU(),\n                    nn.Linear(hidden_dim, hidden_dim)\n                ))\n            self.convs.append(conv)\n            self.batch_norms.append(nn.BatchNorm1d(hidden_dim))\n\n        # Attention mechanism for graph pooling\n        self.pool_attention = nn.Sequential(\n            nn.Linear(hidden_dim, hidden_dim // 2),\n            nn.ReLU(),\n            nn.Linear(hidden_dim // 2, 1)\n        )\n\n        # Projection head for contrastive learning\n        self.projection_head = nn.Sequential(\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, hidden_dim // 2)\n        )\n\n    def forward(self, x, edge_index, batch, return_node_embeddings=False):\n        h = x\n\n        # Pass through GIN layers\n        for i in range(self.num_layers):\n            h_new = self.convs[i](h, edge_index)\n            h_new = self.batch_norms[i](h_new)\n            h_new = F.relu(h_new)\n            h_new = F.dropout(h_new, p=self.dropout, training=self.training)\n\n            # Residual connection\n            if i > 0:\n                h = h + h_new\n            else:\n                h = h_new\n\n        # Optionally return node embeddings directly\n        if return_node_embeddings:\n            return h\n\n        # Apply attention pooling to get graph-level embedding\n        attention_weights = self.pool_attention(h)\n        attention_weights = F.softmax(attention_weights, dim=0)\n\n        graph_embedding = global_add_pool(h * attention_weights, batch)\n\n        # Pass through projection head for contrastive learning\n        return self.projection_head(graph_embedding)", "metadata": {"id": "f732f97f-dcf4-43be-ada2-f37cdcc3f40a"}, "outputs": [], "execution_count": 9}, {"cell_type": "code", "source": "class ContrastiveLoss(nn.Module):\n    def __init__(self, temperature=0.1, lambda_reg=0.01):\n        super().__init__()\n        # Initialize temperature and regularization lambda for the loss\n        self.temperature = temperature\n        self.lambda_reg = lambda_reg\n\n    def forward(self, z_a, z_b):\n        # Compute the contrastive loss between two augmented views of the same graph\n        batch_size = z_a.size(0)\n\n        # Normalize embeddings\n        z_a = F.normalize(z_a, dim=1)\n        z_b = F.normalize(z_b, dim=1)\n\n        # Calculate similarity matrix\n        similarity_matrix = torch.matmul(z_a, z_b.T) / self.temperature\n\n        # Create labels for contrastive loss (diagonal elements are positive pairs)\n        labels = torch.arange(batch_size).to(z_a.device)\n\n        # Compute cross-entropy loss for both directions (a to b and b to a)\n        loss_a = F.cross_entropy(similarity_matrix, labels)\n        loss_b = F.cross_entropy(similarity_matrix.T, labels)\n\n        contrastive_loss = (loss_a + loss_b) / 2\n\n        # Compute regularization loss (variance of embeddings around their mean)\n        z_mean = (z_a + z_b) / 2\n        mean_embedding = z_mean.mean(dim=0)\n        regularization_loss = torch.norm(z_mean - mean_embedding.unsqueeze(0), dim=1).mean()\n\n        # Combine contrastive and regularization losses\n        total_loss = contrastive_loss + self.lambda_reg * regularization_loss\n\n        return total_loss, contrastive_loss, regularization_loss", "metadata": {"id": "685b6d97-5150-4ba5-b0b2-7941be89b483"}, "outputs": [], "execution_count": 10}, {"cell_type": "code", "source": "class ClassificationHead(nn.Module):\n    def __init__(self, input_dim, num_classes, dropout=0.3):\n        super().__init__()\n        # Define a multi-layer perceptron for classification\n        self.classifier = nn.Sequential(\n            nn.Linear(input_dim, input_dim // 2),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(input_dim // 2, input_dim // 4),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(input_dim // 4, num_classes)\n        )\n\n    def forward(self, x):\n        # Pass input through the classifier\n        return self.classifier(x)", "metadata": {"id": "e3dbf4da-1b77-4fe6-9454-4adc00c9e8ad"}, "outputs": [], "execution_count": 11}, {"cell_type": "code", "source": "def create_connection_hash(row):\n    # Create a hash for unique connection identification\n    connection_str = f\"{row['protocol_type']}_{row['service']}_{row['flag']}\"\n    return int(hashlib.md5(connection_str.encode()).hexdigest()[:8], 16) % 10000\n\ndef create_graph_from_connection(row, node_features_dim=10):\n    # Define node roles\n    src_node = 0\n    dst_node = 1\n    protocol_node = 2\n    service_node = 3\n\n    num_nodes = 4\n\n    # Initialize node features\n    node_features = torch.zeros(num_nodes, node_features_dim)\n\n    # Populate node features based on connection attributes\n    node_features[src_node, 0] = row['src_bytes'] / (row['src_bytes'] + row['dst_bytes'] + 1e-8)\n    node_features[src_node, 1] = row['count']\n    node_features[src_node, 2] = row['srv_count']\n    node_features[src_node, 3] = row['same_srv_rate']\n    node_features[src_node, 4] = row['diff_srv_rate']\n\n    node_features[dst_node, 0] = row['dst_bytes'] / (row['src_bytes'] + row['dst_bytes'] + 1e-8)\n    node_features[dst_node, 1] = row['dst_host_count']\n    node_features[dst_node, 2] = row['dst_host_srv_count']\n    node_features[dst_node, 3] = row['dst_host_same_srv_rate']\n    node_features[dst_node, 4] = row['dst_host_diff_srv_rate']\n\n    node_features[protocol_node, 0] = 1.0 if row['protocol_type'] == 'tcp' else 0.5 if row['protocol_type'] == 'udp' else 0.0\n    node_features[protocol_node, 1] = row['duration']\n    node_features[protocol_node, 2] = row['wrong_fragment']\n    node_features[protocol_node, 3] = row['urgent']\n\n    node_features[service_node, 0] = row['hot']\n    node_features[service_node, 1] = row['num_failed_logins']\n    node_features[service_node, 2] = row['logged_in']\n    node_features[service_node, 3] = row['num_compromised']\n\n    # Add additional features to all nodes\n    additional_features = torch.tensor([\n        row['serror_rate'], row['rerror_rate'], row['srv_serror_rate'],\n        row['srv_rerror_rate'], row['dst_host_serror_rate'], row['dst_host_rerror_rate']\n    ])\n\n    for i in range(min(6, node_features_dim - 5)):\n        if i < len(additional_features):\n            node_features[:, 5+i] = additional_features[i]\n\n    # Define edges between nodes\n    edge_index = torch.tensor([\n        [src_node, dst_node, protocol_node, service_node, dst_node, src_node],\n        [dst_node, src_node, src_node, dst_node, protocol_node, service_node]\n    ], dtype=torch.long)\n\n    # Define edge attributes (e.g., bytes transferred, duration)\n    edge_attr = torch.tensor([\n        [row['src_bytes'], row['duration']],\n        [row['dst_bytes'], row['duration']],\n        [row['count'], row['srv_count']],\n        [row['srv_count'], row['count']],\n        [row['dst_host_count'], row['dst_host_srv_count']],\n        [row['dst_host_srv_count'], row['dst_host_count']]\n    ], dtype=torch.float)\n\n    # Return a PyTorch Geometric Data object\n    return Data(x=node_features, edge_index=edge_index, edge_attr=edge_attr)", "metadata": {"id": "a1b7e38e-b104-4d10-81c6-7c13c45f557a"}, "outputs": [], "execution_count": 12}, {"cell_type": "code", "source": "def evaluate_model(encoder, classification_head, data_loader, device):\n    # Set models to evaluation mode\n    encoder.eval()\n    classification_head.eval()\n    \n    predictions = []\n    targets = []\n    probs = []\n    \n    with torch.no_grad():\n        for batch_data, batch_labels in data_loader:\n            batch_data = batch_data.to(device)\n            batch_labels = batch_labels.to(device)\n            \n            # Get embeddings from the encoder\n            embeddings = encoder(batch_data.x, batch_data.edge_index, batch_data.batch)\n            # Get classification outputs from the classification head\n            outputs = classification_head(embeddings)\n            \n            # Calculate probabilities and predicted classes\n            prob = F.softmax(outputs, dim=1)\n            _, predicted = torch.max(outputs, 1)\n            \n            # Store predictions, targets, and probabilities\n            predictions.extend(predicted.cpu().numpy())\n            targets.extend(batch_labels.cpu().numpy())\n            probs.extend(prob[:, 1].cpu().numpy())\n    \n    predictions = np.array(predictions)\n    targets = np.array(targets)\n    probs = np.array(probs)\n    \n    # Calculate various classification metrics\n    metrics = {\n        'accuracy': accuracy_score(targets, predictions),\n        'precision': precision_score(targets, predictions, average='weighted'),\n        'recall': recall_score(targets, predictions, average='weighted'),\n        'f1': f1_score(targets, predictions, average='weighted'),\n        'auc': roc_auc_score(targets, probs)\n    }\n    \n    return metrics, predictions, targets, probs", "metadata": {"id": "36221b37-d8a1-449d-91e6-82a527881068"}, "outputs": [], "execution_count": 13}, {"cell_type": "code", "source": "print(\"Loading and preprocessing data...\")\n\nprint(f\"Dataset shape: {df.shape}\")\n# Display initial class distribution\nclass_counts = df['class'].value_counts()\nprint(f\"Class distribution:\\n{class_counts}\")\n\ntraining_history['class_distributions']['original'] = class_counts.to_dict()\n\n# Create a unique connection ID hash for data leakage checks\ndf['connection_id'] = df.apply(create_connection_hash, axis=1)\n\n# Encode categorical columns\ncategorical_columns = ['protocol_type', 'service', 'flag']\nle_dict = {}\n\nfor col in categorical_columns:\n    le = LabelEncoder()\n    df[col + '_encoded'] = le.fit_transform(df[col].astype(str))\n    le_dict[col] = le\n\n# Convert multi-class labels to binary (normal vs. anomaly)\nbinary_class = (df['class'] != 'normal').astype(int)\ntraining_history['class_distributions']['binary'] = {\n    'normal': int((binary_class == 0).sum()),\n    'anomaly': int((binary_class == 1).sum())\n}\n\n# Perform chronological data splitting\nchronological_split_point = int(len(df) * 0.6)\ntrain_indices = list(range(chronological_split_point))\ntest_indices = list(range(chronological_split_point, len(df)))\n\nprint(f\"Chronological split - Train: {len(train_indices)}, Test: {len(test_indices)}\")\n\n# Further split the training data into pre-training and fine-tuning sets\npretrain_size = int(len(train_indices) * 0.7)\nfinetune_size = len(train_indices) - pretrain_size\n\npretrain_indices = train_indices[:pretrain_size]\nfinetune_indices = train_indices[pretrain_size:]\n\nprint(f\"Pretrain size: {len(pretrain_indices)}, Finetune size: {len(finetune_indices)}\")\n\n# Store dataset split information in training history\ntraining_history['dataset_splits'] = {\n    'total_samples': len(df),\n    'pretrain_size': len(pretrain_indices),\n    'finetune_size': len(finetune_indices),\n    'test_size': len(test_indices)\n}\n\nprint(\"Creating graphs...\")\nall_graphs = []\nall_labels = []\n\n# Iterate through the DataFrame to create a graph for each connection\nprogress_bar = tqdm(range(len(df)), desc=\"Creating graphs\")\nfor i in progress_bar:\n    row = df.iloc[i]\n    graph = create_graph_from_connection(row)\n    all_graphs.append(graph)\n    all_labels.append(binary_class.iloc[i])\n\n    if i % 1000 == 0:\n        progress_bar.set_description(f\"Created {i+1}/{len(df)} graphs\")\n\n# Separate graphs and labels into respective datasets\npretrain_graphs = [all_graphs[i] for i in pretrain_indices]\nfinetune_graphs = [all_graphs[i] for i in finetune_indices]\nfinetune_labels = [all_labels[i] for i in finetune_indices]\ntest_graphs = [all_graphs[i] for i in test_indices]\ntest_labels = [all_labels[i] for i in test_indices]\n\nprint(f\"Pretrain graphs: {len(pretrain_graphs)}\")\nprint(f\"Finetune graphs: {len(finetune_graphs)}, Labels: {len(finetune_labels)}\")\nprint(f\"Test graphs: {len(test_graphs)}, Labels: {len(test_labels)}\")\n\n# Initialize StandardScaler for feature normalization and GraphAugmentation\nscaler = StandardScaler()\naugmentation = GraphAugmentation()\n\n# Create PyTorch Geometric datasets\npretrain_dataset = NetworkGraphDataset(pretrain_graphs, transform=None, scaler=scaler, fit_scaler=True)\nfinetune_dataset = NetworkGraphDataset(finetune_graphs, finetune_labels, scaler=scaler)\ntest_dataset = NetworkGraphDataset(test_graphs, test_labels, scaler=scaler)\n\n# Define model and training parameters\ninput_dim = pretrain_graphs[0].x.size(1)\nhidden_dim = 128\nnum_epochs_pretrain = 50\nnum_epochs_finetune = 30\nbatch_size = 32\nlearning_rate = 0.001\n\n# Store training configuration\ntraining_history['training_config'] = {\n    'input_dim': input_dim,\n    'hidden_dim': hidden_dim,\n    'num_epochs_pretrain': num_epochs_pretrain,\n    'num_epochs_finetune': num_epochs_finetune,\n    'batch_size': batch_size,\n    'learning_rate': learning_rate,\n    'device': str(device)\n}\n\n# Create DataLoaders for each dataset\npretrain_loader = DataLoader(pretrain_dataset, batch_size=batch_size, shuffle=True,\n                           collate_fn=lambda x: Batch.from_data_list(x), drop_last=True)\nfinetune_loader = DataLoader(finetune_dataset, batch_size=batch_size, shuffle=True,\n                           collate_fn=lambda x: (Batch.from_data_list([item[0] for item in x]),\n                                                torch.tensor([item[1] for item in x])), drop_last=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n                        collate_fn=lambda x: (Batch.from_data_list([item[0] for item in x]),\n                                             torch.tensor([item[1] for item in x])))", "metadata": {"id": "7e181071-9885-446c-ae5a-16f6f99be40e"}, "outputs": [{"name": "stdout", "text": "Loading and preprocessing data...\nDataset shape: (25192, 42)\nClass distribution:\nclass\nnormal     13449\nanomaly    11743\nName: count, dtype: int64\nChronological split - Train: 15115, Test: 10077\nPretrain size: 10580, Finetune size: 4535\nCreating graphs...\n", "output_type": "stream"}, {"name": "stderr", "text": "Created 25001/25192 graphs: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 25192/25192 [00:11<00:00, 2108.50it/s]", "output_type": "stream"}, {"name": "stdout", "text": "Pretrain graphs: 10580\nFinetune graphs: 4535, Labels: 4535\nTest graphs: 10077, Labels: 10077\n", "output_type": "stream"}, {"name": "stderr", "text": "\n", "output_type": "stream"}], "execution_count": 14}, {"cell_type": "code", "source": "# Initialize the GraphEncoder and ContrastiveLoss\nencoder = GraphEncoder(input_dim, hidden_dim).to(device)\ncontrastive_loss_fn = ContrastiveLoss().to(device)\n# Initialize optimizer and learning rate scheduler for pre-training\noptimizer = optim.AdamW(encoder.parameters(), lr=learning_rate, weight_decay=1e-4)\nscheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs_pretrain)\n\n# Store encoder parameter count\ntraining_history['model_parameters']['encoder_params'] = sum(p.numel() for p in encoder.parameters())\n\nprint(\"\\nStarting contrastive pre-training...\")\n# Set encoder to training mode\nencoder.train()\n\npretrain_progress = tqdm(range(num_epochs_pretrain), desc=\"Pre-training\", position=0, leave=True)\nfor epoch in pretrain_progress:\n    epoch_start_time = time.time()\n    total_loss = 0\n    total_contrastive = 0\n    total_reg = 0\n    num_batches = 0\n    batch_losses_epoch = []\n\n    for batch_idx, batch in enumerate(pretrain_loader):\n        batch = batch.to(device)\n\n        # Create two augmented views of the batch\n        batch_a = augmentation(batch)\n        batch_b = augmentation(batch)\n\n        batch_a = batch_a.to(device)\n        batch_b = batch_b.to(device)\n\n        # Get embeddings from the encoder for both views\n        z_a = encoder(batch_a.x, batch_a.edge_index, batch_a.batch)\n        z_b = encoder(batch_b.x, batch_b.edge_index, batch_b.batch)\n\n        # Calculate contrastive loss\n        loss, contrastive, reg = contrastive_loss_fn(z_a, z_b)\n\n        # Backpropagation and optimization\n        optimizer.zero_grad()\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(encoder.parameters(), max_norm=1.0) # Gradient clipping\n        optimizer.step()\n\n        # Accumulate loss metrics\n        total_loss += loss.item()\n        total_contrastive += contrastive.item()\n        total_reg += reg.item()\n        num_batches += 1\n        \n        batch_losses_epoch.append(loss.item())\n\n    # Step the learning rate scheduler\n    scheduler.step()\n    \n    epoch_time = time.time() - epoch_start_time\n    training_history['epoch_times'].append(epoch_time)\n\n    # Calculate average losses for the epoch\n    avg_loss = total_loss / num_batches\n    avg_contrastive = total_contrastive / num_batches\n    avg_reg = total_reg / num_batches\n    \n    # Store pre-training metrics in history\n    training_history['pretrain_losses'].append(avg_loss)\n    training_history['pretrain_contrastive_losses'].append(avg_contrastive)\n    training_history['pretrain_reg_losses'].append(avg_reg)\n    training_history['pretrain_learning_rates'].append(scheduler.get_last_lr()[0])\n    training_history['batch_losses'].extend(batch_losses_epoch)\n\n    # Update progress bar\n    pretrain_progress.set_postfix({\n        'Loss': f'{avg_loss:.4f}',\n        'Contrastive': f'{avg_contrastive:.4f}',\n        'Reg': f'{avg_reg:.4f}',\n        'LR': f'{scheduler.get_last_lr()[0]:.6f}',\n        'Time': f'{epoch_time:.2f}s'\n    })", "metadata": {"id": "1cc66674-3ab8-44d6-9926-d515c32f331b"}, "outputs": [{"name": "stdout", "text": "\nStarting contrastive pre-training...\n", "output_type": "stream"}, {"name": "stderr", "text": "Pre-training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 50/50 [06:00<00:00,  7.20s/it, Loss=0.2879, Contrastive=0.2783, Reg=0.9596, LR=0.000000, Time=7.09s]\n", "output_type": "stream"}], "execution_count": 15}, {"cell_type": "code", "source": "print(\"\\nPre-training completed. Starting fine-tuning...\")\n\n# Initialize the ClassificationHead\nclassification_head = ClassificationHead(hidden_dim // 2, 2).to(device)\n# Store classification head parameter count\ntraining_history['model_parameters']['classifier_params'] = sum(p.numel() for p in classification_head.parameters())\ntraining_history['model_parameters']['total_params'] = training_history['model_parameters']['encoder_params'] + training_history['model_parameters']['classifier_params']\n\n# Freeze all encoder parameters except for the last GIN layer\nfor param in encoder.parameters():\n    param.requires_grad = False\n\nfor param in encoder.convs[-1].parameters():\n    param.requires_grad = True\nfor param in encoder.batch_norms[-1].parameters():\n    param.requires_grad = True\n\n# Initialize optimizer for fine-tuning (includes classification head and last encoder layer)\nfinetune_optimizer = optim.AdamW(\n    list(classification_head.parameters()) +\n    list(encoder.convs[-1].parameters()) +\n    list(encoder.batch_norms[-1].parameters()),\n    lr=learning_rate * 0.1, # Use a smaller learning rate for fine-tuning\n    weight_decay=1e-4\n)\n\n# Initialize learning rate scheduler for fine-tuning\nfinetune_scheduler = optim.lr_scheduler.StepLR(finetune_optimizer, step_size=10, gamma=0.5)\n# Define cross-entropy loss for classification\ncriterion = nn.CrossEntropyLoss()\n\n# Set models to training mode\nencoder.train()\nclassification_head.train()\n\nfinetune_progress = tqdm(range(num_epochs_finetune), desc=\"Fine-tuning\", position=0, leave=True)\nbest_val_auc = 0\npatience = 5\npatience_counter = 0\n\nfor epoch in finetune_progress:\n    epoch_start_time = time.time()\n    total_loss = 0\n    correct = 0\n    total = 0\n\n    for batch_data, batch_labels in finetune_loader:\n        batch_data = batch_data.to(device)\n        batch_labels = batch_labels.to(device)\n\n        # Get embeddings from the encoder\n        embeddings = encoder(batch_data.x, batch_data.edge_index, batch_data.batch)\n        # Get classification outputs\n        outputs = classification_head(embeddings)\n\n        # Calculate classification loss\n        loss = criterion(outputs, batch_labels)\n\n        # Backpropagation and optimization\n        finetune_optimizer.zero_grad()\n        loss.backward()\n        # Gradient clipping for fine-tuning\n        torch.nn.utils.clip_grad_norm_(\n            list(classification_head.parameters()) +\n            list(encoder.convs[-1].parameters()) +\n            list(encoder.batch_norms[-1].parameters()),\n            max_norm=1.0\n        )\n        finetune_optimizer.step()\n\n        # Accumulate loss and accuracy metrics\n        total_loss += loss.item()\n        _, predicted = torch.max(outputs.data, 1)\n        total += batch_labels.size(0)\n        correct += (predicted == batch_labels).sum().item()\n\n    # Step the fine-tuning learning rate scheduler\n    finetune_scheduler.step()\n    \n    epoch_time = time.time() - epoch_start_time\n\n    # Calculate average loss and accuracy for the epoch\n    avg_loss = total_loss / len(finetune_loader)\n    accuracy = 100. * correct / total\n    \n    # Store fine-tuning metrics in history\n    training_history['finetune_losses'].append(avg_loss)\n    training_history['finetune_accuracies'].append(accuracy)\n    training_history['finetune_learning_rates'].append(finetune_scheduler.get_last_lr()[0])\n\n    # Evaluate on validation (finetune) set periodically\n    if epoch % 5 == 0:\n        val_metrics, _, _, _ = evaluate_model(encoder, classification_head, finetune_loader, device)\n        training_history['validation_metrics'].append({\n            'epoch': epoch,\n            'metrics': val_metrics\n        })\n\n    # Update progress bar\n    finetune_progress.set_postfix({\n        'Loss': f'{avg_loss:.4f}',\n        'Accuracy': f'{accuracy:.2f}%',\n        'Time': f'{epoch_time:.2f}s'\n    })", "metadata": {"id": "d071d183-d68e-4299-95db-46ae8dcac3fd"}, "outputs": [{"name": "stdout", "text": "\nPre-training completed. Starting fine-tuning...\n", "output_type": "stream"}, {"name": "stderr", "text": "Fine-tuning: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [00:52<00:00,  1.73s/it, Loss=0.0856, Accuracy=97.10%, Time=1.44s]\n", "output_type": "stream"}], "execution_count": 16}, {"cell_type": "code", "source": "print(\"\\nFine-tuning completed. Evaluating on test set...\")\n\n# Set models to evaluation mode for final testing\nencoder.eval()\nclassification_head.eval()\n\n# Evaluate the model on the held-out test set\ntest_metrics, test_predictions, test_targets, test_probs = evaluate_model(encoder, classification_head, test_loader, device)\n\n# Store test metrics in history\ntraining_history['test_metrics'] = test_metrics\ntraining_history['test_predictions'] = test_predictions.tolist()\ntraining_history['test_targets'] = test_targets.tolist()\ntraining_history['test_probabilities'] = test_probs.tolist()\n\nprint(f\"\\nFinal Test Results:\")\nprint(f\"AUC Score: {test_metrics['auc']:.4f}\")\nprint(f\"F1 Score: {test_metrics['f1']:.4f}\")\nprint(f\"Accuracy: {test_metrics['accuracy']:.4f}\")\nprint(f\"Precision: {test_metrics['precision']:.4f}\")\nprint(f\"Recall: {test_metrics['recall']:.4f}\")\n\nprint(\"\\nDetailed Classification Report:\")\nprint(classification_report(test_targets, test_predictions, target_names=['Normal', 'Anomaly']))\n\nprint(\"\\nData Leakage Verification:\")\n# Check for data leakage by comparing connection IDs in train and test sets\ntrain_connection_ids = set(df.iloc[pretrain_indices + finetune_indices]['connection_id'])\ntest_connection_ids = set(df.iloc[test_indices]['connection_id'])\noverlap = train_connection_ids.intersection(test_connection_ids)\noverlap_percentage = len(overlap)/len(test_connection_ids)*100\nprint(f\"Connection ID overlap between train and test: {len(overlap)} ({overlap_percentage:.2f}%)\")\n\ntraining_history['data_leakage_check'] = {\n    'overlap_count': len(overlap),\n    'overlap_percentage': overlap_percentage,\n    'train_connection_ids': len(train_connection_ids),\n    'test_connection_ids': len(test_connection_ids)\n}\n\nprint(f\"\\nModel Summary:\")\nprint(f\"Total parameters: {training_history['model_parameters']['total_params']}\")\nprint(f\"Encoder parameters: {training_history['model_parameters']['encoder_params']}\")\nprint(f\"Classification head parameters: {training_history['model_parameters']['classifier_params']}\")\n\n# Save the complete training history to a JSON file\nwith open('training_history.json', 'w') as f:\n    json.dump(training_history, f, indent=2)\n\n# Prepare data for pre-training visualization and save to CSV\nvisualization_data = pd.DataFrame({\n    'epoch': range(len(training_history['pretrain_losses'])),\n    'pretrain_loss': training_history['pretrain_losses'],\n    'contrastive_loss': training_history['pretrain_contrastive_losses'],\n    'regularization_loss': training_history['pretrain_reg_losses'],\n    'learning_rate': training_history['pretrain_learning_rates']\n})\n\n# Prepare data for fine-tuning visualization and save to CSV\nfinetune_data = pd.DataFrame({\n    'epoch': range(len(training_history['finetune_losses'])),\n    'finetune_loss': training_history['finetune_losses'],\n    'finetune_accuracy': training_history['finetune_accuracies'],\n    'finetune_lr': training_history['finetune_learning_rates']\n})\n\nvisualization_data.to_csv('pretrain_metrics.csv', index=False)\nfinetune_data.to_csv('finetune_metrics.csv', index=False)\n\n# Save test results to a CSV file\ntest_results_df = pd.DataFrame({\n    'predictions': training_history['test_predictions'],\n    'targets': training_history['test_targets'],\n    'probabilities': training_history['test_probabilities']\n})\ntest_results_df.to_csv('test_results.csv', index=False)\n\nprint(\"\\nTraining completed successfully!\")\nprint(\"Visualization data saved to:\")\nprint(\"- training_history.json (complete training history)\")\nprint(\"- pretrain_metrics.csv (pretraining metrics)\")\nprint(\"- finetune_metrics.csv (finetuning metrics)\")\nprint(\"- test_results.csv (test predictions and targets)\")\n\nprint(f\"\\nData Collection Summary:\")\nprint(f\"- Collected {len(training_history['pretrain_losses'])} pretraining epochs\")\nprint(f\"- Collected {len(training_history['finetune_losses'])} finetuning epochs\")\nprint(f\"- Collected {len(training_history['batch_losses'])} batch losses\")\nprint(f\"- Collected {len(training_history['validation_metrics'])} validation checkpoints\")\nprint(f\"- Test set size: {len(training_history['test_predictions'])} samples\")", "metadata": {"id": "94cb048a-2b50-4041-a402-27dcb9d12df1"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "import matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import confusion_matrix, roc_curve, auc\nimport json\n\n# Set style\nplt.style.use('default')\nsns.set_palette(\"Set2\")\n\n# Load training history\nwith open('training_history.json', 'r') as f:\n    training_history = json.load(f)\n\n# Create simple dashboard with key visualizations\nfig, axes = plt.subplots(2, 3, figsize=(15, 10))\n\n# 1. TRAINING LOSSES\naxes[0, 0].plot(training_history['pretrain_losses'], 'b-', linewidth=2, label='Pretraining')\nif training_history['finetune_losses']:\n    start_epoch = len(training_history['pretrain_losses'])\n    finetune_epochs = range(start_epoch, start_epoch + len(training_history['finetune_losses']))\n    axes[0, 0].plot(finetune_epochs, training_history['finetune_losses'], 'r-', linewidth=2, label='Finetuning')\naxes[0, 0].set_title('Training Loss', fontweight='bold')\naxes[0, 0].set_xlabel('Epoch')\naxes[0, 0].set_ylabel('Loss')\naxes[0, 0].legend()\naxes[0, 0].grid(True, alpha=0.3)\n\n# 2. FINETUNING ACCURACY\naxes[0, 1].plot(training_history['finetune_accuracies'], 'g-', linewidth=2, marker='o')\naxes[0, 1].set_title('Finetuning Accuracy', fontweight='bold')\naxes[0, 1].set_xlabel('Epoch')\naxes[0, 1].set_ylabel('Accuracy (%)')\naxes[0, 1].grid(True, alpha=0.3)\n\n# 3. TEST PERFORMANCE METRICS\ntest_metrics = training_history['test_metrics']\nmetrics_names = list(test_metrics.keys())\nmetrics_values = list(test_metrics.values())\nbars = axes[0, 2].bar(metrics_names, metrics_values, color=['skyblue', 'lightgreen', 'orange', 'pink', 'lightcoral'])\naxes[0, 2].set_title('Test Performance', fontweight='bold')\naxes[0, 2].set_ylabel('Score')\naxes[0, 2].set_ylim(0, 1)\n# Add value labels on bars\nfor bar, value in zip(bars, metrics_values):\n    axes[0, 2].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n                   f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\naxes[0, 2].tick_params(axis='x', rotation=45)\n\n# 4. CONFUSION MATRIX\ncm = confusion_matrix(training_history['test_targets'], training_history['test_predictions'])\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', square=True, ax=axes[1, 0],\n            xticklabels=['Normal', 'Anomaly'], yticklabels=['Normal', 'Anomaly'])\naxes[1, 0].set_title('Confusion Matrix', fontweight='bold')\naxes[1, 0].set_xlabel('Predicted')\naxes[1, 0].set_ylabel('Actual')\n\n# 5. ROC CURVE\nfpr, tpr, _ = roc_curve(training_history['test_targets'], training_history['test_probabilities'])\nroc_auc = auc(fpr, tpr)\naxes[1, 1].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC (AUC = {roc_auc:.3f})')\naxes[1, 1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', alpha=0.5)\naxes[1, 1].set_xlim([0.0, 1.0])\naxes[1, 1].set_ylim([0.0, 1.05])\naxes[1, 1].set_xlabel('False Positive Rate')\naxes[1, 1].set_ylabel('True Positive Rate')\naxes[1, 1].set_title('ROC Curve', fontweight='bold')\naxes[1, 1].legend(loc=\"lower right\")\naxes[1, 1].grid(True, alpha=0.3)\n\n# 6. CLASS DISTRIBUTION\nclass_dist = training_history['class_distributions']['binary']\nlabels = list(class_dist.keys())\nsizes = list(class_dist.values())\ncolors = ['lightblue', 'lightcoral']\naxes[1, 2].pie(sizes, labels=labels, autopct='%1.1f%%', colors=colors, startangle=90)\naxes[1, 2].set_title('Class Distribution', fontweight='bold')\n\nplt.tight_layout()\nplt.savefig('key_training_results.png', dpi=300, bbox_inches='tight')\nplt.show()\n\n# SIMPLE TRAINING SUMMARY\nprint(\"=\" * 50)\nprint(\"TRAINING SUMMARY\")\nprint(\"=\" * 50)\nprint(f\"Final Test AUC: {training_history['test_metrics']['auc']:.4f}\")\nprint(f\"Final Test Accuracy: {training_history['test_metrics']['accuracy']:.4f}\")\nprint(f\"Final Test F1 Score: {training_history['test_metrics']['f1']:.4f}\")\nprint(f\"Pretraining Loss Reduction: {training_history['pretrain_losses'][0]:.4f} \u2192 {training_history['pretrain_losses'][-1]:.4f}\")\nprint(f\"Best Finetuning Accuracy: {max(training_history['finetune_accuracies']):.2f}%\")\nprint(\"=\" * 50)", "metadata": {"id": "c4ec19e9-985a-437e-beca-6b898a370d77"}, "outputs": [], "execution_count": null}]}